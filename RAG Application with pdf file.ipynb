{"cells":[{"cell_type":"markdown","metadata":{"id":"R2vT3u2qVxPc"},"source":["# **Project Essentials**"]},{"cell_type":"markdown","metadata":{"id":"6HTLxd1ic6Bc"},"source":["## **What is RAG?**\n","\n","RAG is a technique for augmenting LLM knowledge with additional data.\n","\n","LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model's cutoff date, you need to augment the knowledge of the model with the specific information it needs. The process of bringing the appropriate information and inserting it into the model prompt is known as Retrieval Augmented Generation (RAG).\n","\n","  \n","\n","  Reference : [Langchian RAG Documentation](https://python.langchain.com/v0.2/docs/tutorials/rag/)"]},{"cell_type":"markdown","metadata":{"id":"Bs0g1Pi7WD9Y"},"source":["## **Important Files**\n","\n","Libraries: All tthe libraries used are listed under a repearate file as we are accessing it in the next line.\n","\n","Sample Pdf: [LLM_Research_Paper.pdf](https://drive.google.com/file/d/1rIJpKZyd4D2u6qbPO_hW9kdT-uP0sbMK/view?usp=sharing)\n","\n","\n","You must have a \".env\" file in which you have to add your own OpenAI api key. This is done to maintain privacy while sharing code file."]},{"cell_type":"markdown","metadata":{"id":"kd07YPk1SDcY"},"source":["\n","# **Final Project**"]},{"cell_type":"markdown","metadata":{"id":"uLGYoFlaqIg0"},"source":["### **Installing the required libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"enZ_rNA7Saed"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"RqOdf974ST__"},"source":["### **Loading Environment Variable**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QF-kSR11RvQq"},"outputs":[],"source":["# Importing necessary modules\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","\n","# Setting OPENAI_API_KEY environment variable\n","os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"]},{"cell_type":"markdown","metadata":{"id":"6twwdvr9Sdn4"},"source":["### **Data Ingestion Using PDF file**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"uTuzkhjJgX9f"},"outputs":[],"source":["#Importing PyPDFLoader to ennable pdf readability\n","from langchain_community.document_loaders import PyPDFLoader\n","\n","#Using the sample file\n","loader = PyPDFLoader(\"LLM_Research_Paper.pdf\")"]},{"cell_type":"markdown","metadata":{"id":"catCgccCVc8s"},"source":["### **Loading the data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFATrwKAULLP"},"outputs":[],"source":["#Loading the pdf content to \"docs\"\n","docs = loader.load()\n","docs"]},{"cell_type":"markdown","metadata":{"id":"RxGYuMLXSlA_"},"source":["### **Text Splitting**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"onLE6GR1gjhm"},"outputs":[],"source":["!pip install langchain\n","\n","# Importing RecursiveCharacterTextSplitter to split the retrieved Data\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Assgning parameters like chunk size and overlap\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n","    )\n","\n","# Storing the split documents to \"chunks_documents\"\n","chunk_documents=text_splitter.split_documents(docs)\n","\n","# Display the Chunks\n","chunk_documents"]},{"cell_type":"markdown","metadata":{"id":"5_ODBCHsSuqa"},"source":["### **Embedding**"]},{"cell_type":"markdown","metadata":{"id":"mhQffRSAS42x"},"source":["**Embedding Using FAISS**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Vector embedding using FAISS\n","\n","from langchain_community.embeddings import OpenAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","\n","# Embedding the data chunks using FAISS vectorstores\n","db = FAISS.from_documents(chunk_documents, OpenAIEmbeddings())\n","db"]},{"cell_type":"markdown","metadata":{"id":"6g25peZ7TaID"},"source":["### **Searching**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9c-EWa8gjbO"},"outputs":[],"source":["# Writing the query which will be the search criteria or parameter in this case\n","query= \"\"\n","\n","# Performaing Similarity Search\n","retrieved_result= db.similarity_search(query)\n","\n","# Displaying the results\n","print(retrieved_result)"]},{"cell_type":"markdown","metadata":{"id":"IbP7u3tVEFOE"},"source":["### **Review**\n","\n","\n","In order to do so,\n","*   Open the pdf that you have uploaded  \n","*   Now search for the same query that you entered manually\n","*   This will take you the place in the pdf where you might have the text\n","*   Once done now you know how well the code has performed in different aspect, lets highlight them as well.\n","\n","\n","\n","### Aspects where effeciency can be seen.  \n","1.   Easy Results\n","2.   Reduced time\n","3.   It didnt involve extra background resources or application to oopen the pdf\n","4.   The code is now more effecient and also take less than the previous time.\n","5.   Flexible as we can work on different pdfs and different query as per our requirements.\n"]},{"cell_type":"markdown","metadata":{"id":"aFbA_l_PBW3P"},"source":["## **Project Explantion**"]},{"cell_type":"markdown","metadata":{"id":"N5NkwLCkCwuv"},"source":["Go through [list of Document_loaders](https://python.langchain.com/v0.2/docs/integrations/document_loaders/)\n","\n","The link contains a table that shows feature support for all document loaders available ."]},{"cell_type":"markdown","metadata":{"id":"ZjtYMS7ABQ4R"},"source":["### **Data Ingestion Using Webpages(Optional)**\n","\n","\n","WebBaseLoader\tLoad HTML pages using urllib and parse them with `BeautifulSoup'.\twith Lazy loading and Native async support"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gg1CzpnzBUg9"},"outputs":[],"source":["# Importing necessary modules\n","from langchain_community.document_loaders import WebBaseLoader\n","import bs4\n","\n","# Giving the Website link that we will read\n","loader = WebBaseLoader(\"https://python.langchain.com/v0.2/docs/tutorials/rag/\")\n","\n","# Loading the data to \"docs\"\n","docs = loader.load()\n","docs"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTSF2jDGM1t0iZ3d62C6ZV","provenance":[{"file_id":"1r3KEml1qbCQs5rxDPuxCHjXKy1pUz-SJ","timestamp":1720507107761}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
